{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *`Solution Notebook for Practice Project 2`*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  *Table of Content*\n",
    "\n",
    "## **[Part I: Numpy](#np)**\n",
    "## **[Part II: Pandas](#pd)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"np\"> </a>\n",
    "# *Part I: NUMPY*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1) State differences between Numpy Array and lists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Arrays are homogeneous where as Lists can be homogeneous or heterogeneous\n",
    " - Element wise operation is possible in arrays but not possible in lists\n",
    " - Arrays are very useful for multi-dimensional data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2) Write a Code to create 50 evenly spaced numbers between 0 to 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.20408163,  0.40816327,  0.6122449 ,  0.81632653,\n",
       "        1.02040816,  1.2244898 ,  1.42857143,  1.63265306,  1.83673469,\n",
       "        2.04081633,  2.24489796,  2.44897959,  2.65306122,  2.85714286,\n",
       "        3.06122449,  3.26530612,  3.46938776,  3.67346939,  3.87755102,\n",
       "        4.08163265,  4.28571429,  4.48979592,  4.69387755,  4.89795918,\n",
       "        5.10204082,  5.30612245,  5.51020408,  5.71428571,  5.91836735,\n",
       "        6.12244898,  6.32653061,  6.53061224,  6.73469388,  6.93877551,\n",
       "        7.14285714,  7.34693878,  7.55102041,  7.75510204,  7.95918367,\n",
       "        8.16326531,  8.36734694,  8.57142857,  8.7755102 ,  8.97959184,\n",
       "        9.18367347,  9.3877551 ,  9.59183673,  9.79591837, 10.        ])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(0,10,50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3) Write a Code to create an array of shape (4,5) with random samples with random seed 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.07630829, 0.77991879, 0.43840923, 0.72346518, 0.97798951],\n",
       "       [0.53849587, 0.50112046, 0.07205113, 0.26843898, 0.4998825 ],\n",
       "       [0.67923   , 0.80373904, 0.38094113, 0.06593635, 0.2881456 ],\n",
       "       [0.90959353, 0.21338535, 0.45212396, 0.93120602, 0.02489923]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(7)\n",
    "arr = np.random.random((4,5))\n",
    "arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4) Write a Code to reshape the array created in Q3 into shape (2,10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.07630829, 0.77991879, 0.43840923, 0.72346518, 0.97798951,\n",
       "        0.53849587, 0.50112046, 0.07205113, 0.26843898, 0.4998825 ],\n",
       "       [0.67923   , 0.80373904, 0.38094113, 0.06593635, 0.2881456 ,\n",
       "        0.90959353, 0.21338535, 0.45212396, 0.93120602, 0.02489923]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.reshape(2,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5) Create an 1D array starting from 0 ending with 100 with stepsize 10 and another array starting from 1000 ending with 10000 with stepsize 1000 and then concatenate two arrays created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 10,  20,  30,  40,  50,  60,  70,  80,  90, 100])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr1 = np.arange(10,110,10)\n",
    "arr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1000,  2000,  3000,  4000,  5000,  6000,  7000,  8000,  9000,\n",
       "       10000])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr2 = np.arange(1000,11000,1000)\n",
    "arr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   10,    20,    30,    40,    50,    60,    70,    80,    90,\n",
       "         100,  1000,  2000,  3000,  4000,  5000,  6000,  7000,  8000,\n",
       "        9000, 10000])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr3 = np.concatenate((arr1,arr2))\n",
    "arr3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6) Use array created in Q5 and replace the values lesser than 50 as <50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['<50', '<50', '<50', '<50', '50', '60', '70', '80', '90', '100',\n",
       "       '1000', '2000', '3000', '4000', '5000', '6000', '7000', '8000',\n",
       "       '9000', '10000'], dtype='<U11')"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(arr3<50,'<50',arr3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q7) Write a Code to create 1D, 2D and 3D arrays randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.60054892, 0.9501295 , 0.23030288, 0.54848992, 0.90912837])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand(5) ## 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.13316945, 0.52341258, 0.75040986, 0.66901324],\n",
       "       [0.46775286, 0.20484909, 0.49076589, 0.37238469],\n",
       "       [0.47740115, 0.36589039, 0.83791799, 0.76864751],\n",
       "       [0.31399468, 0.57262533, 0.27604905, 0.45284293],\n",
       "       [0.35297837, 0.65739946, 0.37035108, 0.45909298]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand(5,4) ## 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.09714648, 0.10284749],\n",
       "        [0.7015073 , 0.89047987]],\n",
       "\n",
       "       [[0.1595603 , 0.27557254],\n",
       "        [0.67249153, 0.16430312]],\n",
       "\n",
       "       [[0.70137114, 0.48763522],\n",
       "        [0.68067777, 0.52154819]]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand(3,2,2) ## 3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q8) Write a Code to create an array with 10 random integers within 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([47, 16, 12, 93,  9, 76, 67, 14, 20, 53])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(0,100,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q9) Create a array with an sample data with shape of (5,4) with standard normal distribution with random seed of 201."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(201)\n",
    "arr = np.random.normal(loc=0,scale=1,size=(5,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.31678346, -0.4934171 ,  1.21794581,  0.43677076],\n",
       "       [-0.72769267,  0.43030744, -0.68666532, -0.45301801],\n",
       "       [-0.73285921, -0.75362743, -0.83251892,  0.44987187],\n",
       "       [ 1.80752304, -0.48953136,  0.88158874, -0.69834087],\n",
       "       [-0.0499747 ,  1.90752236, -0.32762267,  1.15003185]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q10) Use the array from Q9 and create a dataframe with index=['L','M','N','O','P'], columns=['A','B','C','D']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>0.316783</td>\n",
       "      <td>-0.493417</td>\n",
       "      <td>1.217946</td>\n",
       "      <td>0.436771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>-0.727693</td>\n",
       "      <td>0.430307</td>\n",
       "      <td>-0.686665</td>\n",
       "      <td>-0.453018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>-0.732859</td>\n",
       "      <td>-0.753627</td>\n",
       "      <td>-0.832519</td>\n",
       "      <td>0.449872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>1.807523</td>\n",
       "      <td>-0.489531</td>\n",
       "      <td>0.881589</td>\n",
       "      <td>-0.698341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E</th>\n",
       "      <td>-0.049975</td>\n",
       "      <td>1.907522</td>\n",
       "      <td>-0.327623</td>\n",
       "      <td>1.150032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          W         X         Y         Z\n",
       "A  0.316783 -0.493417  1.217946  0.436771\n",
       "B -0.727693  0.430307 -0.686665 -0.453018\n",
       "C -0.732859 -0.753627 -0.832519  0.449872\n",
       "D  1.807523 -0.489531  0.881589 -0.698341\n",
       "E -0.049975  1.907522 -0.327623  1.150032"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(arr,index=['A','B','C','D','E'],columns=['W','X','Y','Z'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q11) Find the most frequent value in an numpy 1D array. Use array x = np.array([10,20,66,20,10,30,50,60,70,60,66,12,13,66])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 20 66 20 10 30 50 60 70 60 66 12 13 66]\n",
      "Most frequent value in the array is: 66\n"
     ]
    }
   ],
   "source": [
    "x = np.array([10,20,66,20,10,30,50,60,70,60,66,12,13,66])\n",
    "print(x)\n",
    "  \n",
    "print(\"Most frequent value in the array is:\",np.bincount(x).argmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q12) Write a Code to Flatten a 2d array into 1d array. Use array: np.array([[1,2,3],[8,9,10],[11,22,33]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3],\n",
       "       [ 8,  9, 10],\n",
       "       [11, 22, 33]])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1 = np.array([[1,2,3],[8,9,10],[11,22,33]])\n",
    "a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  8,  9, 10, 11, 22, 33])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pd\"> </a>\n",
    "# *Part II: PANDAS*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About Dataset Provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **YouTube Dislikes Dataset:**\n",
    "This dataset contains information about trending YouTube videos from August 2020 to December 2021 for the USA, Canada, and Great Britain.\n",
    "- **Context and Content:**\n",
    "Youtube announced the decision to hide the number of dislikes from users around November 2021. However, the official YouTube Data API allowed you to get information about dislikes until December 13, 2021.\n",
    "- This dataset contains the latest possible information about dislikes,likes,views and more which was collected just before December 13. The information was collected by videos that had been trending in the USA, Canada, and Great Britain for a year prior.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1) Import required libraries and read the provided dataset (youtube_dislike_dataset.csv) and retrieve top 5 and bottom 5 records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>title</th>\n",
       "      <th>channel_id</th>\n",
       "      <th>channel_title</th>\n",
       "      <th>published_at</th>\n",
       "      <th>view_count</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>tags</th>\n",
       "      <th>description</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--0bCF-iK2E</td>\n",
       "      <td>Jadon Sancho  Magical Skills &amp; Goals</td>\n",
       "      <td>UC6UL29enLNe4mqwTfAyeNuw</td>\n",
       "      <td>Bundesliga</td>\n",
       "      <td>2021-07-01 10:00:00</td>\n",
       "      <td>1048888</td>\n",
       "      <td>19515</td>\n",
       "      <td>226</td>\n",
       "      <td>1319</td>\n",
       "      <td>football soccer ftbol alemn Bundesliga season ...</td>\n",
       "      <td>Enjoy the best skills and goals from Jadon San...</td>\n",
       "      <td>Respect to Dortmund fans,must be sad losing hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>--14w5SOEUs</td>\n",
       "      <td>Migos - Avalanche (Official Video)</td>\n",
       "      <td>UCGIelM2Dj3zza3xyV3pL3WQ</td>\n",
       "      <td>MigosVEVO</td>\n",
       "      <td>2021-06-10 16:00:00</td>\n",
       "      <td>15352638</td>\n",
       "      <td>359277</td>\n",
       "      <td>7479</td>\n",
       "      <td>18729</td>\n",
       "      <td>Migos Avalanche Quality Control Music/Motown R...</td>\n",
       "      <td>Watch the the official video for Migos - \"Aval...</td>\n",
       "      <td>Migos just makes me want to live my live to th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>--40TEbZ9Is</td>\n",
       "      <td>Supporting Actress in a Comedy: 73rd Emmys</td>\n",
       "      <td>UClBKH8yZRcM4AsRjDVEdjMg</td>\n",
       "      <td>Television Academy</td>\n",
       "      <td>2021-09-20 01:03:32</td>\n",
       "      <td>925281</td>\n",
       "      <td>11212</td>\n",
       "      <td>401</td>\n",
       "      <td>831</td>\n",
       "      <td></td>\n",
       "      <td>Hannah Waddingham wins the Emmy for Supporting...</td>\n",
       "      <td>Hannah's energy bursts through any screen. Wel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>--4tfbSyYDE</td>\n",
       "      <td>JO1'YOUNG (JO1 ver.)' PERFORMANCE VIDEO</td>\n",
       "      <td>UCsmXiDP8S40uBeJYxvyulmA</td>\n",
       "      <td>JO1</td>\n",
       "      <td>2021-03-03 10:00:17</td>\n",
       "      <td>2641597</td>\n",
       "      <td>39131</td>\n",
       "      <td>441</td>\n",
       "      <td>3745</td>\n",
       "      <td>PRODUCE101JAPAN              JO1   TheSTAR STA...</td>\n",
       "      <td>JO1'YOUNG (JO1 ver.)' PERFORMANCE VIDEO\\n\\n---...</td>\n",
       "      <td>youngVer&gt;&lt;  REN is really PERFECT. It's not ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>--DKkzWVh-E</td>\n",
       "      <td>Why Retaining Walls Collapse</td>\n",
       "      <td>UCMOqf8ab-42UUQIdVoKwjlQ</td>\n",
       "      <td>Practical Engineering</td>\n",
       "      <td>2021-12-07 13:00:00</td>\n",
       "      <td>715724</td>\n",
       "      <td>32887</td>\n",
       "      <td>367</td>\n",
       "      <td>1067</td>\n",
       "      <td>retaining wall New Jersey highway Direct Conne...</td>\n",
       "      <td>One of the most important (and innocuous) part...</td>\n",
       "      <td>Keep up with all my projects here: https://pr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                       title  \\\n",
       "0  --0bCF-iK2E        Jadon Sancho  Magical Skills & Goals   \n",
       "1  --14w5SOEUs          Migos - Avalanche (Official Video)   \n",
       "2  --40TEbZ9Is  Supporting Actress in a Comedy: 73rd Emmys   \n",
       "3  --4tfbSyYDE     JO1'YOUNG (JO1 ver.)' PERFORMANCE VIDEO   \n",
       "4  --DKkzWVh-E                Why Retaining Walls Collapse   \n",
       "\n",
       "                 channel_id          channel_title         published_at  \\\n",
       "0  UC6UL29enLNe4mqwTfAyeNuw             Bundesliga  2021-07-01 10:00:00   \n",
       "1  UCGIelM2Dj3zza3xyV3pL3WQ              MigosVEVO  2021-06-10 16:00:00   \n",
       "2  UClBKH8yZRcM4AsRjDVEdjMg     Television Academy  2021-09-20 01:03:32   \n",
       "3  UCsmXiDP8S40uBeJYxvyulmA                    JO1  2021-03-03 10:00:17   \n",
       "4  UCMOqf8ab-42UUQIdVoKwjlQ  Practical Engineering  2021-12-07 13:00:00   \n",
       "\n",
       "   view_count   likes  dislikes  comment_count  \\\n",
       "0     1048888   19515       226           1319   \n",
       "1    15352638  359277      7479          18729   \n",
       "2      925281   11212       401            831   \n",
       "3     2641597   39131       441           3745   \n",
       "4      715724   32887       367           1067   \n",
       "\n",
       "                                                tags  \\\n",
       "0  football soccer ftbol alemn Bundesliga season ...   \n",
       "1  Migos Avalanche Quality Control Music/Motown R...   \n",
       "2                                                      \n",
       "3  PRODUCE101JAPAN              JO1   TheSTAR STA...   \n",
       "4  retaining wall New Jersey highway Direct Conne...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Enjoy the best skills and goals from Jadon San...   \n",
       "1  Watch the the official video for Migos - \"Aval...   \n",
       "2  Hannah Waddingham wins the Emmy for Supporting...   \n",
       "3  JO1'YOUNG (JO1 ver.)' PERFORMANCE VIDEO\\n\\n---...   \n",
       "4  One of the most important (and innocuous) part...   \n",
       "\n",
       "                                            comments  \n",
       "0  Respect to Dortmund fans,must be sad losing hi...  \n",
       "1  Migos just makes me want to live my live to th...  \n",
       "2  Hannah's energy bursts through any screen. Wel...  \n",
       "3  youngVer><  REN is really PERFECT. It's not ju...  \n",
       "4   Keep up with all my projects here: https://pr...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('youtube_dislike_dataset.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>title</th>\n",
       "      <th>channel_id</th>\n",
       "      <th>channel_title</th>\n",
       "      <th>published_at</th>\n",
       "      <th>view_count</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>tags</th>\n",
       "      <th>description</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37417</th>\n",
       "      <td>zzd4ydafGR0</td>\n",
       "      <td>Lil Tjay - Calling My Phone (feat. 6LACK) [Off...</td>\n",
       "      <td>UCEB4a5o_6KfjxHwNMnmj54Q</td>\n",
       "      <td>Lil Tjay</td>\n",
       "      <td>2021-02-12 05:03:49</td>\n",
       "      <td>120408275</td>\n",
       "      <td>2180780</td>\n",
       "      <td>35871</td>\n",
       "      <td>81360</td>\n",
       "      <td>Lil Tjay Steady Calling My Phone Calling My Ph...</td>\n",
       "      <td>Official video for \"Calling My Phone\" by Lil T...</td>\n",
       "      <td>'DESTINED 2 WIN' OUT NOW !! https://liltjay.ln...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37418</th>\n",
       "      <td>zziBybeSAtw</td>\n",
       "      <td>PELICANS at LAKERS | FULL GAME HIGHLIGHTS | Ja...</td>\n",
       "      <td>UCWJ2lWNubArHWmf3FIHbfcQ</td>\n",
       "      <td>NBA</td>\n",
       "      <td>2021-01-16 05:39:05</td>\n",
       "      <td>2841917</td>\n",
       "      <td>20759</td>\n",
       "      <td>1049</td>\n",
       "      <td>2624</td>\n",
       "      <td>NBA G League Basketball game-0022000187 Lakers...</td>\n",
       "      <td>PELICANS at LAKERS | FULL GAME HIGHLIGHTS | Ja...</td>\n",
       "      <td>Montrezl Harrell is going crazy with the rebou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37419</th>\n",
       "      <td>zzk09ESX7e0</td>\n",
       "      <td>[MV]  (MAMAMOO) - Where Are We Now</td>\n",
       "      <td>UCuhAUMLzJxlP1W7mEk0_6lA</td>\n",
       "      <td>MAMAMOO</td>\n",
       "      <td>2021-06-02 09:00:10</td>\n",
       "      <td>13346678</td>\n",
       "      <td>720854</td>\n",
       "      <td>4426</td>\n",
       "      <td>90616</td>\n",
       "      <td>MAMAMOO  WAW  WAW MAMAMOO WAW Where Are We Now...</td>\n",
       "      <td>[MV]  (MAMAMOO) - Where Are We Now\\n\\nInstagra...</td>\n",
       "      <td>I honestly do not know why this song hit so ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37420</th>\n",
       "      <td>zzmQEb0Em5I</td>\n",
       "      <td>FELLIPE ESCUDERO- Master Podcast  #12</td>\n",
       "      <td>UC8NjnNWMsRqq11NYvHAQb1g</td>\n",
       "      <td>Master Podcast</td>\n",
       "      <td>2020-10-20 20:59:30</td>\n",
       "      <td>252057</td>\n",
       "      <td>19198</td>\n",
       "      <td>1234</td>\n",
       "      <td>1471</td>\n",
       "      <td>master masterpodcast lord lord vinheteiro z z ...</td>\n",
       "      <td>DOCTOR HAIR\\nhttps://www.thedoctorhair.com/?fb...</td>\n",
       "      <td>Foi um prazer passar esta tarde com vocs debat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37421</th>\n",
       "      <td>zzxPZwaA-8w</td>\n",
       "      <td>Gareth Bale brace secures dramatic comeback on...</td>\n",
       "      <td>UCEg25rdRZXg32iwai6N6l0w</td>\n",
       "      <td>Tottenham Hotspur</td>\n",
       "      <td>2021-05-23 21:00:31</td>\n",
       "      <td>2252090</td>\n",
       "      <td>34063</td>\n",
       "      <td>868</td>\n",
       "      <td>2004</td>\n",
       "      <td>Spurs Tottenham Hotspur   Tottenham Leicester ...</td>\n",
       "      <td>Two minute highlights from Tottenham Hotspur's...</td>\n",
       "      <td>Thank you Kane for everything you have given t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          video_id                                              title  \\\n",
       "37417  zzd4ydafGR0  Lil Tjay - Calling My Phone (feat. 6LACK) [Off...   \n",
       "37418  zziBybeSAtw  PELICANS at LAKERS | FULL GAME HIGHLIGHTS | Ja...   \n",
       "37419  zzk09ESX7e0                 [MV]  (MAMAMOO) - Where Are We Now   \n",
       "37420  zzmQEb0Em5I              FELLIPE ESCUDERO- Master Podcast  #12   \n",
       "37421  zzxPZwaA-8w  Gareth Bale brace secures dramatic comeback on...   \n",
       "\n",
       "                     channel_id      channel_title         published_at  \\\n",
       "37417  UCEB4a5o_6KfjxHwNMnmj54Q           Lil Tjay  2021-02-12 05:03:49   \n",
       "37418  UCWJ2lWNubArHWmf3FIHbfcQ                NBA  2021-01-16 05:39:05   \n",
       "37419  UCuhAUMLzJxlP1W7mEk0_6lA            MAMAMOO  2021-06-02 09:00:10   \n",
       "37420  UC8NjnNWMsRqq11NYvHAQb1g     Master Podcast  2020-10-20 20:59:30   \n",
       "37421  UCEg25rdRZXg32iwai6N6l0w  Tottenham Hotspur  2021-05-23 21:00:31   \n",
       "\n",
       "       view_count    likes  dislikes  comment_count  \\\n",
       "37417   120408275  2180780     35871          81360   \n",
       "37418     2841917    20759      1049           2624   \n",
       "37419    13346678   720854      4426          90616   \n",
       "37420      252057    19198      1234           1471   \n",
       "37421     2252090    34063       868           2004   \n",
       "\n",
       "                                                    tags  \\\n",
       "37417  Lil Tjay Steady Calling My Phone Calling My Ph...   \n",
       "37418  NBA G League Basketball game-0022000187 Lakers...   \n",
       "37419  MAMAMOO  WAW  WAW MAMAMOO WAW Where Are We Now...   \n",
       "37420  master masterpodcast lord lord vinheteiro z z ...   \n",
       "37421  Spurs Tottenham Hotspur   Tottenham Leicester ...   \n",
       "\n",
       "                                             description  \\\n",
       "37417  Official video for \"Calling My Phone\" by Lil T...   \n",
       "37418  PELICANS at LAKERS | FULL GAME HIGHLIGHTS | Ja...   \n",
       "37419  [MV]  (MAMAMOO) - Where Are We Now\\n\\nInstagra...   \n",
       "37420  DOCTOR HAIR\\nhttps://www.thedoctorhair.com/?fb...   \n",
       "37421  Two minute highlights from Tottenham Hotspur's...   \n",
       "\n",
       "                                                comments  \n",
       "37417  'DESTINED 2 WIN' OUT NOW !! https://liltjay.ln...  \n",
       "37418  Montrezl Harrell is going crazy with the rebou...  \n",
       "37419  I honestly do not know why this song hit so ha...  \n",
       "37420  Foi um prazer passar esta tarde com vocs debat...  \n",
       "37421  Thank you Kane for everything you have given t...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2) Check the info of the dataframe and write your inferences on datatypes and shape of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 37422 entries, 0 to 37421\n",
      "Data columns (total 12 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   video_id       37422 non-null  object\n",
      " 1   title          37422 non-null  object\n",
      " 2   channel_id     37422 non-null  object\n",
      " 3   channel_title  37422 non-null  object\n",
      " 4   published_at   37422 non-null  object\n",
      " 5   view_count     37422 non-null  int64 \n",
      " 6   likes          37422 non-null  int64 \n",
      " 7   dislikes       37422 non-null  int64 \n",
      " 8   comment_count  37422 non-null  int64 \n",
      " 9   tags           37422 non-null  object\n",
      " 10  description    37422 non-null  object\n",
      " 11  comments       37264 non-null  object\n",
      "dtypes: int64(4), object(8)\n",
      "memory usage: 3.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37422, 12)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are *12* columns and *37422* rows.\n",
    "- There are *8* columns datatypes as object and rest all are integer datatype.\n",
    "- We can consider column video_id as unique indentifer for all the rows.\n",
    "- We can convert column published_at to pandas date_time format.\n",
    "- We can observe some null values in the column comments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3) Check for the Percentage of the Null values and drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "video_id         0.00\n",
       "title            0.00\n",
       "channel_id       0.00\n",
       "channel_title    0.00\n",
       "published_at     0.00\n",
       "view_count       0.00\n",
       "likes            0.00\n",
       "dislikes         0.00\n",
       "comment_count    0.00\n",
       "tags             0.00\n",
       "description      0.00\n",
       "comments         0.42\n",
       "dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(df.isnull().sum()/len(df)*100,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can see there is *0.42%* of records in column records is null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37264, 12)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4) Check the statistical summary of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>view_count</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comment_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.726400e+04</td>\n",
       "      <td>3.726400e+04</td>\n",
       "      <td>3.726400e+04</td>\n",
       "      <td>3.726400e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.710821e+06</td>\n",
       "      <td>1.672867e+05</td>\n",
       "      <td>4.996434e+03</td>\n",
       "      <td>9.966953e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.431304e+07</td>\n",
       "      <td>5.384931e+05</td>\n",
       "      <td>3.075194e+04</td>\n",
       "      <td>1.173465e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.036800e+04</td>\n",
       "      <td>2.200000e+01</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.141305e+05</td>\n",
       "      <td>1.331725e+04</td>\n",
       "      <td>2.827500e+02</td>\n",
       "      <td>9.140000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.321860e+06</td>\n",
       "      <td>4.255600e+04</td>\n",
       "      <td>7.980000e+02</td>\n",
       "      <td>2.347000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.674527e+06</td>\n",
       "      <td>1.309665e+05</td>\n",
       "      <td>2.466250e+03</td>\n",
       "      <td>6.212000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.322797e+09</td>\n",
       "      <td>3.183768e+07</td>\n",
       "      <td>2.397733e+06</td>\n",
       "      <td>1.607103e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         view_count         likes      dislikes  comment_count\n",
       "count  3.726400e+04  3.726400e+04  3.726400e+04   3.726400e+04\n",
       "mean   5.710821e+06  1.672867e+05  4.996434e+03   9.966953e+03\n",
       "std    2.431304e+07  5.384931e+05  3.075194e+04   1.173465e+05\n",
       "min    2.036800e+04  2.200000e+01  3.000000e+00   1.000000e+00\n",
       "25%    5.141305e+05  1.331725e+04  2.827500e+02   9.140000e+02\n",
       "50%    1.321860e+06  4.255600e+04  7.980000e+02   2.347000e+03\n",
       "75%    3.674527e+06  1.309665e+05  2.466250e+03   6.212000e+03\n",
       "max    1.322797e+09  3.183768e+07  2.397733e+06   1.607103e+07"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5) Convert datatype of column published_at from object to pandas datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['published_at'] = pd.to_datetime(df['published_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 37264 entries, 0 to 37421\n",
      "Data columns (total 1 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   published_at  37264 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](1)\n",
      "memory usage: 582.2 KB\n"
     ]
    }
   ],
   "source": [
    "df[['published_at']].info()  ## We can see that we sucessfully changed the dataype from object to datetime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6) Create a column as 'published_month' using the column published_at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['published_month'] = df['published_at'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>title</th>\n",
       "      <th>channel_id</th>\n",
       "      <th>channel_title</th>\n",
       "      <th>published_at</th>\n",
       "      <th>view_count</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>tags</th>\n",
       "      <th>description</th>\n",
       "      <th>comments</th>\n",
       "      <th>published_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--0bCF-iK2E</td>\n",
       "      <td>Jadon Sancho  Magical Skills &amp; Goals</td>\n",
       "      <td>UC6UL29enLNe4mqwTfAyeNuw</td>\n",
       "      <td>Bundesliga</td>\n",
       "      <td>2021-07-01 10:00:00</td>\n",
       "      <td>1048888</td>\n",
       "      <td>19515</td>\n",
       "      <td>226</td>\n",
       "      <td>1319</td>\n",
       "      <td>football soccer ftbol alemn Bundesliga season ...</td>\n",
       "      <td>Enjoy the best skills and goals from Jadon San...</td>\n",
       "      <td>Respect to Dortmund fans,must be sad losing hi...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>--14w5SOEUs</td>\n",
       "      <td>Migos - Avalanche (Official Video)</td>\n",
       "      <td>UCGIelM2Dj3zza3xyV3pL3WQ</td>\n",
       "      <td>MigosVEVO</td>\n",
       "      <td>2021-06-10 16:00:00</td>\n",
       "      <td>15352638</td>\n",
       "      <td>359277</td>\n",
       "      <td>7479</td>\n",
       "      <td>18729</td>\n",
       "      <td>Migos Avalanche Quality Control Music/Motown R...</td>\n",
       "      <td>Watch the the official video for Migos - \"Aval...</td>\n",
       "      <td>Migos just makes me want to live my live to th...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                 title  \\\n",
       "0  --0bCF-iK2E  Jadon Sancho  Magical Skills & Goals   \n",
       "1  --14w5SOEUs    Migos - Avalanche (Official Video)   \n",
       "\n",
       "                 channel_id channel_title        published_at  view_count  \\\n",
       "0  UC6UL29enLNe4mqwTfAyeNuw    Bundesliga 2021-07-01 10:00:00     1048888   \n",
       "1  UCGIelM2Dj3zza3xyV3pL3WQ     MigosVEVO 2021-06-10 16:00:00    15352638   \n",
       "\n",
       "    likes  dislikes  comment_count  \\\n",
       "0   19515       226           1319   \n",
       "1  359277      7479          18729   \n",
       "\n",
       "                                                tags  \\\n",
       "0  football soccer ftbol alemn Bundesliga season ...   \n",
       "1  Migos Avalanche Quality Control Music/Motown R...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Enjoy the best skills and goals from Jadon San...   \n",
       "1  Watch the the official video for Migos - \"Aval...   \n",
       "\n",
       "                                            comments  published_month  \n",
       "0  Respect to Dortmund fans,must be sad losing hi...                7  \n",
       "1  Migos just makes me want to live my live to th...                6  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)  ## We can see that we successfully created another column published_month."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q7) Replace the numbers in column published_month as names of the months i,e., 1 as 'Jan', 2 as 'Feb' and so on....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['published_month'] = df['published_month'].replace({1:'Jan',2:'Feb',3:'March',4:'April',5:'May',6:'June',\n",
    "                                                      7:'July',8:'Aug',9:'Sep',10:'Oct',11:'Nov',12:'Dec'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     July\n",
       "1     June\n",
       "2      Sep\n",
       "3    March\n",
       "Name: published_month, dtype: object"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['published_month'].head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q8) Find the minimum and maximum value of the view_count, likes, dislikes and comment_count and write your inferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "view_count       20368\n",
       "likes               22\n",
       "dislikes             3\n",
       "comment_count        1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['view_count','likes','dislikes','comment_count']].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "view_count       1322796924\n",
       "likes              31837675\n",
       "dislikes            2397733\n",
       "comment_count      16071029\n",
       "dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['view_count','likes','dislikes','comment_count']].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can see that the mimimum view_count is *20368* and max is *1322796924.*\n",
    "- The mimimum likes is *22* and max is *31837675.*\n",
    "- The mimimum dislikes is *3* and max is *2397733.*\n",
    "- The mimimum comment_count is *1* and max is *16071029.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q9) Find the count of unique video_id, channel_id and channel_title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37264"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['video_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10891"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['channel_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10813"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['channel_title'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q10) Find the top10 channel names having the highest number of videos in the dataset and the bottom10 having lowest number of videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "channel_title\n",
       "Sky Sports Football    533\n",
       "The United Stand       301\n",
       "BT Sport               246\n",
       "NBA                    209\n",
       "NFL                    162\n",
       "WWE                    122\n",
       "SSSniperWolf            99\n",
       "SSundee                 98\n",
       "FORMULA 1               87\n",
       "NHL                     86\n",
       "Name: video_id, dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('channel_title')['video_id'].count().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "channel_title\n",
       "   SilverName                   1\n",
       "Miniatur Wunderland             1\n",
       "MiniBloxia                      1\n",
       "Mini Muka                       1\n",
       "Mini Ladd                       1\n",
       "MindYourLogic                   1\n",
       "Mind Body Tonic With Dr Sita    1\n",
       "Mimi Ar                         1\n",
       "Millyz                          1\n",
       "Milkair                         1\n",
       "Name: video_id, dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('channel_title')['video_id'].count().sort_values(ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q11) Find the title of the video which has the maximum number of likes and the title of the video having minimum likes and write your inferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>likes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BTS () 'Dynamite' Official MV</th>\n",
       "      <td>31837675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  likes\n",
       "title                                  \n",
       "BTS () 'Dynamite' Official MV  31837675"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(df,index=['title'],values=['likes'],aggfunc=np.max).sort_values(by='likes',ascending=False).head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We can see that 'BTS Dynamite Offical Music Video' is having the highest number of likes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>likes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Leading the Charge | Circle K</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               likes\n",
       "title                               \n",
       "Leading the Charge | Circle K     22"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(df,index=['title'],values=['likes'],aggfunc=np.max).sort_values(by='likes',ascending=True).head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 'Leading the charge | Circle K' is having lowest number of likes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q12) Find the title of the video which has the maximum number of dislikes and the title of the video having minimum dislikes and write your inferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dislikes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cuties | Official Trailer | Netflix</th>\n",
       "      <td>2397733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     dislikes\n",
       "title                                        \n",
       "Cuties | Official Trailer | Netflix   2397733"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(df,index=['title'],values=['dislikes'],aggfunc=np.max).sort_values(by='dislikes',ascending=False).head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 'Cuties | Offical Trailer | Netflix' has the highest number of dislikes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dislikes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tims For Good: A Taste Of The Familiar</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        dislikes\n",
       "title                                           \n",
       "Tims For Good: A Taste Of The Familiar         3"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(df,index=['title'],values=['dislikes'],aggfunc=np.max).sort_values(by='dislikes',ascending=True).head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 'Tims For Good: A Taste Of The Familiar' has the lowest number of dislikes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
